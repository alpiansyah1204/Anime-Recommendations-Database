# -*- coding: utf-8 -*-
"""ML terapan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tYUk_J9AY5TazMv6nFwU8Cpqt0xElGBb

#Import Library

melakukan import lib yang akan digunakan
"""

from zipfile import ZipFile
import numpy as np 
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from pathlib import Path
from keras import layers
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer

"""#Import kaggle

menginstall kaggle
"""

pip install -q kaggle

"""data loading"""

import os
os.environ['KAGGLE_USERNAME'] = "alpiansyahrizqi"
os.environ['KAGGLE_KEY'] = "4ec2871806d4a125d51415bdc1e5a75a"

"""mengunduh dataset diabetes"""

!kaggle datasets download -d CooperUnion/anime-recommendations-database

"""mengekstrak file zip yang telah diunduh"""

!unzip -q anime-recommendations-database.zip -d .

"""#Import dataset

Import dataset kedalam variable
"""

df_anime = pd.read_csv('/content/anime.csv')
df_rating = pd.read_csv('/content/rating.csv')

"""#Univariate Exploratory Data Analysis

melihat 5 data teratas pada dataset anime
"""

df_anime.head()

"""melihat total data anime"""

print('Jumlah data anime: ', len(df_anime['anime_id'].unique()))

"""melihat jumlah genre anime pada dataset"""

genres = df_anime['genre'].str.split(',').explode()

print('Jumlah genre anime: ', len(genres.unique()))
genres.value_counts(ascending=True).plot(kind='barh', figsize=(20, 20))

"""melihat 5 data teratas pada dataset rating"""

df_rating.head()

"""melihat lagi dataset rating """

print('Jumlah user yang memberikan penilaian: ', len(df_rating['user_id'].unique()))
print('Jumlah anime yang pernah dinilai user: ', len(df_rating['anime_id'].unique()))
print('Jumlah data penilaian anime: ', len(df_rating))

"""Hanya mengambil 5000 jumlah data"""

df_rating = df_rating.drop(range(20000, 7813737))
df_rating

"""melihat deskripsi pada dataset rating """

df_rating.describe().T

"""mengubah nilai rating -1 ke dalam NaN"""

df_rating["rating"].replace({-1: np.nan}, inplace=True)
df_rating

"""jika ada nilai NA, menghapus baris atau kolom itu."""

df_rating = df_rating.dropna(axis = 0, how ='any')
df_rating

"""menghitung jumlah data null pada df_anime"""

df_anime.isnull().sum()

"""menghitung jumlah data null df_rating"""

df_rating.isnull().sum()

"""mengatasi data kosong dengan cara menghapusnya """

df_anime =  df_anime.dropna()
df_anime.isnull().sum()

"""# Content Based Filtering

TF-IDF Vectorizer
"""

tf = TfidfVectorizer()
tf.fit(df_anime['genre'])

"""membuat matrik"""

tfidf_matrix = tf.fit_transform(df_anime['genre']) 

tfidf_matrix.shape

"""return representasi matriks padat dari matriks ini."""

tfidf_matrix.todense()

"""Membuat dataframe untuk melihat tf-idf matrix"""

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=df_anime.name
).sample(22, axis=1).sample(10, axis=0)

"""**Cosine Similarity**
Menghitung cosine similarity pada matrix tf-idf
"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""* Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama anime
* Melihat similarity matrix pada setiap anime
"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=df_anime['name'], columns=df_anime['name'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(20, axis=0)

"""Rekomendasi anime berdasarkan kemiripan dataframe"""

import tensorflow as tf

def anime_recommendations(nama_anime, similarity_data=cosine_sim_df, items=df_anime[['name', 'genre']], k=5):
    
    index = similarity_data.loc[:,nama_anime].to_numpy().argpartition(
        range(-1, -k, -1))
    
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    closest = closest.drop(nama_anime, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""Uji Coba"""

df_anime[df_anime.name.eq('Boku no Hero Academia')]

"""hasil uji coba"""

result = anime_recommendations('Boku no Hero Academia')
result

"""presisi dari model yang dibuat"""

a = 0

for row in result.itertuples():
  if (row.genre == 'Action', 'Comedy', 'School', 'Shounen', 'Super Power'):
    a += 1

precision = (a/5)*100
print("presisi darin model yang dibuat {}%".format(precision))

"""# Collaborative Based Filtering

membuat dataset baru
"""

df = df_rating

"""Encoding"""

user_ids = df['user_id'].unique().tolist()
print('list user_id: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

"""* Mengubah anime_id menjadi list tanpa nilai yang sama
* Melakukan proses encoding anime_id
* Melakukan proses encoding angka ke anime_id
"""

anime_ids = df['anime_id'].unique().tolist()

anime_to_anime_encoded = {x: i for i, x in enumerate(anime_ids)}

anime_encoded_to_anime = {i: x for i, x in enumerate(anime_ids)}

"""Mapping user_id dan anime_id kedalam dataframe user dan anime """

df['user'] = df['user_id'].map(user_to_user_encoded)

df['anime'] = df['anime_id'].map(anime_to_anime_encoded)

"""

*   Mendapatkan jumlah user
*   Mendapatkan jumlah rating
*   Mengubah rating menjadi nilai float
* melihat Nilai minimum rating
* melihat Nilai maksimal rating

"""

num_users = len(user_to_user_encoded)
print(num_users)

num_anime = len(anime_encoded_to_anime)
print(num_anime)

min_rating = min(df['rating'])

max_rating = max(df['rating'])
 
print('Number of User: {}, Number of Anime: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_anime, min_rating, max_rating
))

""" Mengacak dataset"""

df = df.sample(frac=1, random_state=42)
df

"""membagi data train dan validasi dengan komposisi 80:20"""

x = df[['user', 'anime']].values

y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""Fungsi Rekomendasi"""

class RecommenderNet(tf.keras.Model):

  def __init__(self, num_users, num_anime, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_anime = num_anime
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.anime_embedding = layers.Embedding(
        num_anime,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.anime_bias = layers.Embedding(num_anime, 1)
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    anime_vector = self.anime_embedding(inputs[:, 1])
    anime_bias = self.anime_bias(inputs[:, 1])
 
    dot_user_anime = tf.tensordot(user_vector, anime_vector, 2) 
 
    x = dot_user_anime + user_bias + anime_bias
    
    return tf.nn.sigmoid(x)

"""Compile Model"""

model = RecommenderNet(num_users, num_anime, 50)
 
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Training Model"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""Visualisasi Metrik"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Mendapatkan Rekomendasi Resto"""

anime_df = df_anime
df = df_rating

userID = df.user_id.sample(1).iloc[0]
anime_watched_by_user = df[df.user_id == userID]
 
anime_not_watched = anime_df[~anime_df['anime_id'].isin(anime_watched_by_user.anime_id.values)]['anime_id'] 
anime_not_watched = list(
    set(anime_not_watched)
    .intersection(set(anime_to_anime_encoded.keys()))
)
 
anime_not_watched = [[anime_to_anime_encoded.get(x)] for x in anime_not_watched]
user_encoder = user_to_user_encoded.get(userID)
user_anime_array = np.hstack(
    ([[user_encoder]] * len(anime_not_watched), anime_not_watched)
)

"""memperoleh rekomendasi anime"""

from tensorflow import keras

ratings = model.predict(user_anime_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_anime_ids = [
    anime_encoded_to_anime.get(anime_not_watched[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(userID))
print('===' * 9)
print('Anime with high ratings from user')
print('----' * 8)
 
top_anime_user = (
    anime_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .anime_id.values
)
 
anime_df_rows = anime_df[anime_df['anime_id'].isin(top_anime_user)]
for row in anime_df_rows.itertuples():
    print(row.name, ':', row.genre)
 
print('----' * 8)
print('Top 10 anime recommendation')
print('----' * 8)
 
recommended_anime = anime_df[anime_df['anime_id'].isin(recommended_anime_ids)]
for row in recommended_anime.itertuples():
    print(row.name, ':', row.genre)

"""**test**"""